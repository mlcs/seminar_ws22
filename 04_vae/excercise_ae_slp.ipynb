{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise on Autoencoder of Sea level pressure data\n",
    "\n",
    "**Goal:** Aim of this excercise is to implement an Autoencoder (AE) similar to the tutorial but this time for the sea level pressure in the North Atlantic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy as ctp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "plt.style.use(\"./../paper.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Familierize yourself with the data\n",
    "\n",
    "Sea level pressure (SLP) in the North Atlantic highly affects the climate over Europe. \n",
    "\n",
    "The monthly SLP data from 1950-1979 and 1979-2021 are taken from [Copernicus ERA5](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means?tab=overview). The data are cropped over the Northern Atlantic 20°-80°N, 90°W-40°E, regridded on a $5^\\circ \\times 5^\\circ$ resolution, detrended and then subtracted from their monthly climatology. The data can be found in ```04_vae/data/slpa_...```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "da = xr.open_dataset(\"./data/slpa_1950_2021.nc\")['slpa']\n",
    "\n",
    "# Plot last year december, i.e. '2015-12'\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,8), subplot_kw=dict(\n",
    "    projection= ctp.crs.PlateCarree())\n",
    ")\n",
    "da.sel(time='2015-12').plot(ax=ax1, transform=ctp.crs.PlateCarree())\n",
    "ax1.coastlines()\n",
    "da.sel(time='2021-12').plot(ax=ax2, transform=ctp.crs.PlateCarree())\n",
    "ax2.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The North Atlantic oscillation (NAO)\n",
    "\n",
    "The NAO is a weather phenomenon over the North Atlantic Ocean characterized by differences in SLP between the Icelandic Low and the Azores high. The NAO can be either in positive or negative phase depending on the sign of the differences. [Wiki](https://en.wikipedia.org/wiki/North_Atlantic_oscillation)\n",
    "\n",
    "There are different representative time-series of the NAO. One is based on pressure differences between certain points (Icelandic Low and the Azores high) [see [ClimateDataGuide](https://climatedataguide.ucar.edu/climate-data/hurrell-north-atlantic-oscillation-nao-index-station-based)] and the other is based on Principal Component Analysis [see [ClimateDataGuide](https://climatedataguide.ucar.edu/climate-data/hurrell-north-atlantic-oscillation-nao-index-pc-based)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 1**: Construct the station-based NAO index, i.e. the SLP differences between Lisbon and Reykjavík.*\n",
    "\n",
    "Hint:\n",
    "- Select the location of Lisbon (lat=64, lon=21) and Reykjavik (lat=38, lon=9)\n",
    "- Normalize each time-series by its standard deviation using the normalize function, $x_{norm} = \\frac{x-\\bar{x}}{s}$ with $\\bar{x}$ is the mean and $s$ is the standard deviation (see [standard score normalization](https://en.wikipedia.org/wiki/Standard_score))\n",
    "\n",
    "- Subtract the time-series from another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(da):\n",
    "    \"\"\"Normalize data by its standard deviation.\n",
    "\n",
    "    x_norm = (x - mean_x)/ std_x\n",
    "    \n",
    "    Args:\n",
    "        da (xr.DataArray): Input time-series.\n",
    "\n",
    "    Returns:\n",
    "        (xr.DataArray) Normalized time-series.\n",
    "    \"\"\"\n",
    "    flatten = da.stack(temp=da.dims)\n",
    "    mean = flatten.mean(skipna=True)\n",
    "    std = flatten.std(skipna=True)\n",
    "    norm_da = (flatten - mean) / std\n",
    "\n",
    "    return norm_da.unstack('temp')\n",
    "\n",
    "\n",
    "# Compute the station-based index and plot the time series\n",
    "# Your Code here\n",
    "# ==============\n",
    "\n",
    "\n",
    "# =============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess your data\n",
    "\n",
    "As shown in the tutorial we need to define a Dataset class for training our Autoencoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 2**: Normalize the dataset in the init function.*\n",
    "\n",
    "Hint:\n",
    "- use the normalize function implemented before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLPA(Dataset):\n",
    "    \"\"\"Dataset of SSTA used for pytorch.\n",
    "\n",
    "    Args:\n",
    "        dataarray (xr.DataArray): Dataarray containing SSTA. \n",
    "    \"\"\"\n",
    "    def __init__(self, dataarray):\n",
    "        self.time = dataarray['time'].data\n",
    "        self.lat = dataarray['lat'].data\n",
    "        self.lon = dataarray['lon'].data\n",
    "        \n",
    "        # Normalize dataarray by standard deviation\n",
    "        # Overwrite \n",
    "        self.dataarray = None\n",
    "        # Your Code here\n",
    "        # ===================================\n",
    "\n",
    "\n",
    "        # ====================================\n",
    "        \n",
    "        # Flatten map to vector\n",
    "        X = self.dataarray.data.reshape(self.dataarray.shape[0], -1)\n",
    "        # Remove Nans in vector\n",
    "        self.idx_nan = np.isnan(X[0,:])\n",
    "        self.X = X[:, ~self.idx_nan]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of datapoints.\"\"\"\n",
    "        return len(self.dataarray)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Required function to get items of dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index to get datapoint.\n",
    "\n",
    "        Returns:\n",
    "            x (torch.Tensor): Datapoint of dimension (channel, lat, lon)\n",
    "            l (dict): Label of datapoint. In this case just the index.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x = torch.from_numpy(self.X[idx]).float()\n",
    "        label = {'idx': idx}\n",
    "\n",
    "        return x, label\n",
    "    \n",
    "    def get_map(self, x, name=None):\n",
    "        \"\"\"Reshape flattened vector with removed NaNs to xarray map.\n",
    "\n",
    "        Args:\n",
    "            data (torch.tensor): (x_dim) Flatten datapoint with NaNs removed\n",
    "\n",
    "        Return:\n",
    "            map (np.ndarray): 2d-map\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(x):\n",
    "            x = x.to('cpu').detach().numpy()\n",
    "\n",
    "        # Create array with NaNs\n",
    "        x_map = np.ones((len(self.lat) * len(self.lon))) * np.NaN\n",
    "        # fill array with sample\n",
    "        x_map[~self.idx_nan] = x\n",
    "\n",
    "        da_map = xr.DataArray(\n",
    "            data=np.reshape(x_map, (len(self.lat), len(self.lon))),\n",
    "            dims=['lat', 'lon'],\n",
    "            coords=dict(lat=self.lat, lon=self.lon)\n",
    "        )\n",
    "        return da_map \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SLPA(da)\n",
    "# Sample datapoint\n",
    "x, l = dataset[0]\n",
    "x_dim = x.shape[0]\n",
    "print(f\"Shape of datapoint: {x_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = int(len(dataset) * 0.8)\n",
    "(train_data, val_data) = torch.utils.data.random_split(dataset, [n_training, len(dataset) - n_training])\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Adapt the following Autoencoder class by using an encoder and decoder architecture with two linear layers, where the number of hidden nodes is 265.\n",
    "\n",
    "Hints: \n",
    "- We also used a Linear encoder and decoder architecture in the tutorial\n",
    "- Check out the pytorch documentation of [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    \"\"\"Auto encoder.\n",
    "\n",
    "    Args:\n",
    "        z_dim (int): Dimension of latent space. \n",
    "        encoder ([type]): Encoder NN.\n",
    "        decoder ([type]): Decoder NN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.device = torch.device(\n",
    "                'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Your Code here\n",
    "        # ===============================================================================\n",
    "\n",
    "        \n",
    "        # ===============================================================================\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Pass through encoder and decoder.\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): (batch, x_dim) Input to AE.\n",
    "        \n",
    "        Return:\n",
    "            x_hat (tensor): (batch, x_dim ) Reconstruction of x.\n",
    "            z (tensor): (batch, z_dim) Vector in latent space.\n",
    "        \"\"\"\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        return x_hat, z\n",
    "    \n",
    "    def loss(self, x):\n",
    "        \"\"\"Loss function of AE.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): (batch, x_dim) Input to AE.\n",
    "\n",
    "        Returns:\n",
    "            rec_loss (torch.Tensor): Reconstruction loss between input and rec.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encode and decoder input \n",
    "        x_hat, z = self.forward(x)\n",
    "        # Mean square error between reconstructed and input\n",
    "        rec_loss_pointwise = F.mse_loss(x_hat, x, reduction='none')\n",
    "        # Sum of point wise MSE\n",
    "        rec_loss = torch.sum(torch.flatten(rec_loss_pointwise, start_dim=1), dim=-1)\n",
    "        \n",
    "        return rec_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize AE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 2\n",
    "ae = AE(x_dim, z_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** How many trainable parameter does our model have now?\n",
    "\n",
    "Hints: \n",
    "- You can calculate the number using the input dimension, number of hidden layers and z dimension\n",
    "- We also used a function to print the number of training parameters in the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code here\n",
    "# ==============\n",
    "\n",
    "\n",
    "# ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Compared to the Linear architecture in the tutorial, CNN architecture have a much smaller number of parameters by performing equal performances on 2d data. One main reason is that they make use of the spatial correlation between neighboring points.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an NN\n",
    "\n",
    "The training proceedure is the same es in the tutorial. We train the NN by computing the loss for each minibatch and update the gradients using backpropagation. We iterate $N$ epochs over the whole training data. No gradients are computed for the validation data.\n",
    "\n",
    "*Optional: You can try different learning rates and epochs or even optimizers if you have time in the end.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer):\n",
    "    \"\"\"Train model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to train\n",
    "        dataloader (torch.Dataloader): Dataloader of trainingsdata.\n",
    "        optimizer (torch.optim): Optimizer of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        mean_epoch_loss (float): training loss of one epoch\n",
    "    \"\"\"\n",
    "    # set model into training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Set gradients to zero in the beginning of each batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # encoding and decoding\n",
    "        data, _ = data\n",
    "        data = data.to(model.device)\n",
    "\n",
    "        # loss function\n",
    "        loss = model.loss(data)\n",
    "\n",
    "        # backward prop and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    mean_epoch_loss = epoch_loss / len(dataloader)\n",
    "\n",
    "    return mean_epoch_loss\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader):\n",
    "    \"\"\"Validate model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): VAE model to train.\n",
    "        dataloader (torch.Dataloader): Dataloader of validation data.\n",
    "\n",
    "    Returns:\n",
    "        mean_epoch_loss (float): Validation loss of one epoch.\n",
    "    \"\"\"\n",
    "    # Set model into validation mode\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    # For validation no gradients are computed\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            data, _ = data\n",
    "            data = data.to(model.device)\n",
    "\n",
    "            # loss function\n",
    "            loss = model.loss(data)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    mean_epoch_loss = epoch_loss / len(dataloader)\n",
    "\n",
    "    return mean_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training loop\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=learning_rate)    \n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    val_epoch_loss = validate_epoch(\n",
    "        ae, val_loader\n",
    "    )\n",
    "    train_epoch_loss = train_epoch(\n",
    "        ae, train_loader, optimizer\n",
    "    )\n",
    "\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f}\")\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    val_loss.append(val_epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the loss to see if our model learned somethin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss, label='training')\n",
    "ax.plot(val_loss, label='validation')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Plot the input and reconstruction of the autoencoder for a qualitative comparison.\n",
    "\n",
    "Hint:\n",
    "- have a look at the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random inputs from validataion dataset\n",
    "x, l = val_data[np.random.randint(0, len(val_data))]\n",
    "\n",
    "# Your Code here\n",
    "# ===============\n",
    "# 1. encode and decode input\n",
    "\n",
    "\n",
    "# 2. Transform x_rec back to map using get_map(x_rec)\n",
    "\n",
    "\n",
    "# 3. Plotting\n",
    "\n",
    "\n",
    "# =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space\n",
    "\n",
    "We plot the latent space and analyze which features have been compressed in the low dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(model, dataloader):\n",
    "    \"\"\"Encoding dataset and store encoding.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): AE model.\n",
    "        dataloader (torch.Dataloader): Dataloader \n",
    "\n",
    "    Returns:\n",
    "        encode (dict): Dictionary with encodings.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        encode = dict()\n",
    "        for i, x in enumerate(dataloader):\n",
    "            x, l = x\n",
    "            out = model.forward(x.to(model.device))\n",
    "            z = out[1]\n",
    "            if i == 0:\n",
    "                encode['z'] = z.cpu().detach().numpy()\n",
    "                encode['idx'] = l['idx']\n",
    "            else:\n",
    "                encode['z'] = np.vstack([encode['z'], z.cpu().detach().numpy()])\n",
    "                encode['idx'] = np.concatenate((encode['idx'], l['idx']))\n",
    "    return encode\n",
    "\n",
    "encode = encoding(ae, train_loader)\n",
    "\n",
    "# Plot the encoding\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(encode['z'][:,0], encode['z'][:,1], 'ko')\n",
    "ax.set_xlabel(r\"$z_1$\")\n",
    "ax.set_ylabel(r\"$z_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Similar to the tutorial we want to see if the positive and negative phase of the NAO are seperated in the latent space. Choose the condition where the NOA index is > 2.0 for the positive phase and NOA index < -2.0 for the negative phase.\n",
    "\n",
    "Hint:\n",
    "- find the time indices where the stated conditions are valid\n",
    "- plot the encoding $z$ for these time indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code here\n",
    "# ==============\n",
    "\n",
    "\n",
    "\n",
    "# ================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent traverse\n",
    "\n",
    "We can traverse the latent space across different dimensions, as was shown in the tutorial.\n",
    "\n",
    "**Optional:** You can try different traversal directions. What is a typical positive and negative NAO pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_start = torch.Tensor([[0,0]])\n",
    "z_eps = torch.Tensor([1,0])\n",
    "z_range = torch.linspace(-5, 5, 5)\n",
    "\n",
    "# Create traverse through latent space\n",
    "z_samples = z_start.repeat(len(z_range), 1 ) + z_range.unsqueeze(1) * z_eps\n",
    "\n",
    "\n",
    "# Plot latent space\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(encode['z'][:,0], encode['z'][:,1], 'ko', label='encoding')\n",
    "ax.plot(z_samples[:,0], z_samples[:,1], '-o', label='traverse', \n",
    "        markersize=10, linewidth=3)\n",
    "ax.set_xlabel(r\"$z_1$\")\n",
    "ax.set_ylabel(r\"$z_2$\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode z\n",
    "with torch.no_grad():\n",
    "    traverse = ae.decoder(z_samples.to(ae.device))\n",
    "    \n",
    "# Plot reconstructions\n",
    "fig, axs = plt.subplots(\n",
    "    1, len(z_range), figsize=(len(z_range)*5, 3), \n",
    "    subplot_kw=dict(projection= ctp.crs.PlateCarree())\n",
    ")\n",
    "for i, rec in enumerate(traverse):\n",
    "    da_rec = train_data.dataset.get_map(rec)\n",
    "    da_rec.plot(ax=axs[i], transform=ctp.crs.PlateCarree(), vmin=-4, vmax=4, cmap=mpl.cm.RdBu_r)\n",
    "    axs[i].coastlines()\n",
    "    axs[i].set_title(f\"z={z_samples[i].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of AE to PCA\n",
    "\n",
    "AE learn complex non-linear transformations to represent the data. PCA is only a linear transformation often used for dimensionality reduction. We can compare the latent spaces of both methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Normalize and flatten data\n",
    "da_norm = normalize(da)\n",
    "X = da_norm.data.reshape(da_norm.shape[0], -1)\n",
    "\n",
    "# Apply PCA\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the first EOF map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    2, 1, figsize=(8, n_components*3), \n",
    "    subplot_kw=dict(projection= ctp.crs.PlateCarree())\n",
    ")\n",
    "for i in range(n_components):\n",
    "    eof = xr.DataArray(\n",
    "        data = pca.components_[i].reshape(da.shape[1:]),\n",
    "        dims=da.dims[1:],\n",
    "        coords=[da['lat'], da['lon']]\n",
    "    )\n",
    "    eof.plot(ax=axs[i], transform=ctp.crs.PlateCarree(),cmap=mpl.cm.RdBu_r)\n",
    "    axs[i].coastlines()\n",
    "    axs[i].set_title(f\"EOF {i+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise7:** Plot the latent space of the PCA where you color points by their NAO phase, i.e. NAO index is > 2.0 for the positive phase and NOA index < -2.0 for the negative phase. Is the latent space of PCA different to AE?\n",
    "\n",
    "Hint:\n",
    "- The latent space encoding of the PCA can be obtained by ```z = pca.transform(X)```\n",
    "- Use the NAO index computed before to select the index where the conditions are true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code here\n",
    "# ==============\n",
    "# 1. Get PCA latent space \n",
    "\n",
    "\n",
    "# 2. Get indices where positive and negative condition holds\n",
    "\n",
    "\n",
    "# 3. Plot latent space\n",
    "\n",
    "\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00063bf70f766062587712624157a59fa903cf059af4fcc1d1b5871e64a2c30f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('seminarEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
